"""
åƒé—® API LLM å¼•æ“
Qwen API LLM Engine Implementation

Phase 1.3: ä½¿ç”¨é˜¿é‡Œäº‘åƒé—® API å®ç°å¯¹è¯ç”Ÿæˆ
"""
import logging
import os
from typing import List, Dict, Any, Optional

try:
    import dashscope
    from dashscope import Generation
    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False

from .engine import LLMEngine

logger = logging.getLogger(__name__)


class QwenLLMEngine(LLMEngine):
    """
    åƒé—® API LLM å¼•æ“

    ä½¿ç”¨é˜¿é‡Œäº‘ DashScope API è°ƒç”¨åƒé—®å¤§æ¨¡å‹
    """

    # æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
    MODELS = {
        "qwen-turbo": "qwen-turbo",          # å¿«é€Ÿå“åº”ï¼Œé€‚åˆå®æ—¶å¯¹è¯
        "qwen-plus": "qwen-plus",            # å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦
        "qwen-max": "qwen-max",              # æœ€å¼ºæ€§èƒ½
        "qwen-turbo-latest": "qwen-turbo-latest",
    }

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "qwen-turbo",
        temperature: float = 0.7,
        max_tokens: int = 3000,
        max_tokens_long: int = 8000,
        enable_history: bool = True,
        max_history: int = 10,
        system_prompt: Optional[str] = None,
        system_prompt_long: Optional[str] = None,
        long_text_keywords: Optional[list] = None
    ):
        """
        åˆå§‹åŒ–åƒé—® LLM å¼•æ“

        Args:
            api_key: DashScope API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
            model: æ¨¡å‹åç§° (qwen-turbo/qwen-plus/qwen-max)
            temperature: æ¸©åº¦å‚æ•° (0.0-1.0)ï¼Œè¶Šé«˜è¶Šéšæœº
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°ï¼ˆé»˜è®¤æ¨¡å¼ï¼‰
            max_tokens_long: é•¿æ–‡æœ¬æ¨¡å¼æœ€å¤§ token æ•°ï¼ˆç”¨äºè®²æ•…äº‹ç­‰ï¼‰
            enable_history: æ˜¯å¦å¯ç”¨å¯¹è¯å†å²
            max_history: æœ€å¤§å¯¹è¯å†å²è½®æ•°
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆç®€æ´æ¨¡å¼ï¼‰ï¼Œç”¨äºè®¾å®šåŠ©æ‰‹è§’è‰²å’Œé£æ ¼
            system_prompt_long: ç³»ç»Ÿæç¤ºè¯ï¼ˆé•¿æ–‡æœ¬æ¨¡å¼ï¼‰ï¼Œç”¨äºè¯¦ç»†å›ç­”
            long_text_keywords: é•¿æ–‡æœ¬æ£€æµ‹å…³é”®è¯åˆ—è¡¨
        """
        if not DASHSCOPE_AVAILABLE:
            raise ImportError(
                "dashscope åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install dashscope"
            )

        # API Key
        self._api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        if not self._api_key or self._api_key == "sk-your-api-key-here":
            raise ValueError(
                "DashScope API Key æœªé…ç½®ï¼Œè¯·åœ¨ config.yaml ä¸­è®¾ç½® llm.api_key "
                "æˆ–è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡"
            )

        # è®¾ç½® API Key
        dashscope.api_key = self._api_key

        # æ¨¡å‹é…ç½®ï¼ˆæ”¯æŒä»»æ„æ¨¡å‹åç§°ï¼‰
        self._model = model
        self._model_name = model

        # å¦‚æœæ˜¯å·²çŸ¥çš„åƒé—®æ¨¡å‹ï¼Œè®°å½•æç¤ºä¿¡æ¯
        if model in self.MODELS:
            logger.info(f"ä½¿ç”¨åƒé—®æ¨¡å‹: {model}")
        else:
            logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: {model}")

        # ç”Ÿæˆå‚æ•°
        self._temperature = max(0.0, min(1.0, temperature))
        self._max_tokens = max(1, max_tokens)
        self._max_tokens_long = max(1, max_tokens_long)
        self._long_text_keywords = long_text_keywords or [
            "è®²ä¸ªæ•…äº‹", "è®²æ•…äº‹", "è¯¦ç»†è¯´è¯´", "å±•å¼€è®²è®²",
            "å¤šè¯´ä¸€ç‚¹", "å®Œæ•´ä»‹ç»", "è¯¦ç»†æè¿°"
        ]

        # å¯¹è¯å†å²
        self._enable_history = enable_history
        self._max_history = max(1, max_history)
        self._conversation_history: List[Dict[str, str]] = []

        # ç³»ç»Ÿæç¤ºè¯
        self._system_prompt = system_prompt
        self._system_prompt_long = system_prompt_long
        if system_prompt:
            logger.info(f"å·²è®¾ç½®ç³»ç»Ÿæç¤ºè¯ï¼Œè§’è‰²: {system_prompt.split('ã€‚')[0] if 'ã€‚' in system_prompt else system_prompt[:50]}...")
        if system_prompt_long:
            logger.info(f"å·²è®¾ç½®é•¿æ–‡æœ¬ç³»ç»Ÿæç¤ºè¯")

        logger.info(f"åƒé—® LLM å¼•æ“åˆå§‹åŒ–å®Œæˆ: {self._model}")

    def _detect_long_text_mode(self, message: str) -> bool:
        """
        æ£€æµ‹ç”¨æˆ·æ¶ˆæ¯æ˜¯å¦éœ€è¦é•¿æ–‡æœ¬å›å¤

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯

        Returns:
            bool: æ˜¯å¦éœ€è¦é•¿æ–‡æœ¬æ¨¡å¼
        """
        if not message:
            return False

        message_lower = message.lower()
        for keyword in self._long_text_keywords:
            if keyword.lower() in message_lower:
                logger.info(f"æ£€æµ‹åˆ°é•¿æ–‡æœ¬éœ€æ±‚å…³é”®è¯: '{keyword}'")
                return True
        return False

    def generate(
        self,
        prompt: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        **kwargs
    ) -> str:
        """
        ç”Ÿæˆå›å¤

        Args:
            prompt: ç”¨æˆ·è¾“å…¥çš„æç¤ºè¯
            conversation_history: å¯¹è¯å†å²
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            str: ç”Ÿæˆçš„å›å¤æ–‡æœ¬
        """
        result = self.chat(prompt, conversation_history, **kwargs)
        return result["reply"]

    def chat(
        self,
        message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        å¯¹è¯æ¥å£ï¼ˆå¸¦å®Œæ•´è¿”å›ä¿¡æ¯ï¼‰

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å²
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokens ç­‰ï¼‰

        Returns:
            dict: åŒ…å«å›å¤å’Œå…¶ä»–ä¿¡æ¯çš„å­—å…¸
        """
        if not message:
            return {
                "reply": "",
                "usage": {},
                "model": self._model_name,
                "finish_reason": "empty_input",
            }

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []

        # æ£€æµ‹æ˜¯å¦éœ€è¦é•¿æ–‡æœ¬æ¨¡å¼
        use_long_text_mode = self._detect_long_text_mode(message)
        max_tokens = self._max_tokens_long if use_long_text_mode else self._max_tokens

        # æ·»åŠ ç³»ç»Ÿæç¤ºè¯ï¼ˆæ ¹æ®æ¨¡å¼åŠ¨æ€é€‰æ‹©ï¼‰
        system_prompt = kwargs.get("system_prompt", self._system_prompt)
        if use_long_text_mode and self._system_prompt_long:
            # é•¿æ–‡æœ¬æ¨¡å¼ï¼šä½¿ç”¨é•¿æ–‡æœ¬ç³»ç»Ÿæç¤ºè¯
            system_prompt = kwargs.get("system_prompt_long", self._system_prompt_long)
            logger.info("ğŸ“– ä½¿ç”¨é•¿æ–‡æœ¬ç³»ç»Ÿæç¤ºè¯")
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # æ·»åŠ å¯¹è¯å†å²
        history = conversation_history or self._conversation_history
        if history:
            # é™åˆ¶å†å²é•¿åº¦
            if len(history) > self._max_history:
                history = history[-self._max_history:]
            messages.extend(history)

        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append({"role": "user", "content": message})

        if use_long_text_mode:
            logger.info(f"ğŸ“– é•¿æ–‡æœ¬æ¨¡å¼ (max_tokens={max_tokens})")
        else:
            logger.debug(f"æ ‡å‡†æ¨¡å¼ (max_tokens={max_tokens})")

        # è°ƒç”¨ API
        try:
            response = Generation.call(
                model=self._model,
                messages=messages,
                temperature=kwargs.get("temperature", self._temperature),
                max_tokens=kwargs.get("max_tokens", max_tokens),  # ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„max_tokens
                result_format="message",
            )

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                logger.error(f"API è°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
                return {
                    "reply": f"æŠ±æ­‰ï¼ŒAPI è°ƒç”¨å¤±è´¥ï¼ˆ{response.code}ï¼‰",
                    "usage": {},
                    "model": self._model_name,
                    "finish_reason": "api_error",
                }

            # æå–å›å¤
            reply = response.output.choices[0].message.content

            # æ›´æ–°å¯¹è¯å†å²
            if self._enable_history:
                self._conversation_history.append({"role": "user", "content": message})
                self._conversation_history.append({"role": "assistant", "content": reply})

                # é™åˆ¶å†å²é•¿åº¦
                if len(self._conversation_history) > self._max_history * 2:
                    self._conversation_history = self._conversation_history[-self._max_history * 2:]

            return {
                "reply": reply,
                "usage": {
                    "input_tokens": response.usage.input_tokens,
                    "output_tokens": response.usage.output_tokens,
                    "total_tokens": response.usage.input_tokens + response.usage.output_tokens,
                },
                "model": self._model_name,
                "finish_reason": response.output.choices[0].finish_reason,
            }

        except Exception as e:
            logger.error(f"ç”Ÿæˆå›å¤å¤±è´¥: {e}", exc_info=True)
            return {
                "reply": f"æŠ±æ­‰ï¼Œç”Ÿæˆå›å¤æ—¶å‡ºé”™ï¼š{str(e)}",
                "usage": {},
                "model": self._model_name,
                "finish_reason": "error",
            }

    def is_ready(self) -> bool:
        """
        æ£€æŸ¥å¼•æ“æ˜¯å¦å°±ç»ª

        Returns:
            bool: æ˜¯å¦å°±ç»ª
        """
        return DASHSCOPE_AVAILABLE and bool(self._api_key)

    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯

        Returns:
            dict: æ¨¡å‹ä¿¡æ¯
        """
        info = {
            "name": self._model_name,
            "provider": "é˜¿é‡Œäº‘ DashScope",
            "model": self._model,
            "temperature": self._temperature,
            "max_tokens": self._max_tokens,
            "enable_history": self._enable_history,
            "max_history": self._max_history,
        }
        if self._system_prompt:
            # åªè¿”å›ç³»ç»Ÿæç¤ºè¯çš„å‰100ä¸ªå­—ç¬¦
            info["system_prompt"] = self._system_prompt[:100] + "..." if len(self._system_prompt) > 100 else self._system_prompt
        return info

    def reset_conversation(self) -> None:
        """
        é‡ç½®å¯¹è¯ä¸Šä¸‹æ–‡

        æ¸…ç©ºå¯¹è¯å†å²ï¼Œå¼€å§‹æ–°çš„å¯¹è¯
        """
        self._conversation_history = []
        logger.info("å¯¹è¯å†å²å·²é‡ç½®")

    def get_conversation_history(self) -> List[Dict[str, str]]:
        """
        è·å–å½“å‰å¯¹è¯å†å²

        Returns:
            list: å¯¹è¯å†å²
        """
        return self._conversation_history.copy()
