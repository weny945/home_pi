# 人脸识别与物品识别功能 - 技术实现方案

## 版本信息
- **文档版本**: 1.0
- **创建日期**: 2026-02-03
- **目标平台**: 树莓派 5 (ARM64)

---

## 功能概述

### 功能 1：人脸识别与个性化问候
- **独立模式**: 无需唤醒词，持续监测家庭成员
- **识别到成员**: 根据配置的个性化问候语进行语音欢迎
- **场景**: 门铃、自动迎宾、家庭助理

### 功能 2：唤醒后物品识别
- **触发方式**: 唤醒"胡桃"后，说"这是什么"或"拍照识别"
- **识别方式**: 摄像头拍照 → 调用多模态 LLM（如千问 VL / GPT-4V）
- **场景**: 学习辅助、物品查询、视觉问答

---

## 核心技术栈

### 人脸识别模块
```
摄像头捕获    →  OpenCV VideoCapture（USB UVC 免驱）
人脸检测      →  RetinaFace ONNX（~16MB）
人脸识别      →  ArcFace ONNX（MobileNet backbone，~12MB）
推理引擎      →  onnxruntime 1.23.2（已安装，ARM64 稳定）
特征匹配      →  numpy cosine similarity
存储          →  JSON（姓名映射）+ npy（embedding 向量）
```

### 物品识别模块
```
摄像头拍照    →  OpenCV VideoCapture
图像编码      →  Base64
多模态 LLM    →  千问 VL / GPT-4V / Claude 3 Vision
结果输出      →  TTS 语音播报 + 控制台显示
```

---

## 性能预估（树莓派 5）

### 人脸识别延迟
| 步骤 | 延迟 |
|------|------|
| 帧捕获 + 缩放 | ~10ms |
| RetinaFace 检测 | ~100-150ms |
| ArcFace 特征提取 | ~50-100ms |
| 10人 cosine 匹配 | <1ms |
| **单帧总延迟** | **~200-300ms** |

**识别速度**: 约 3-5 FPS（日常场景够用）

### 内存占用预估
| 项目 | 占用 |
|------|------|
| 当前已用 | 4.9GB |
| 人脸模型（检测+识别） | +150-250MB |
| 物品识别（临时） | +50MB |
| **剩余可用** | ~2.5GB |

**优化策略**:
- 人脸识别和 STT 模型分时加载，不同时驻留内存
- 物品识别仅在唤醒后临时激活，用完即释放

---

## 项目结构

```
src/
├── face/                           # 人脸识别模块
│   ├── __init__.py
│   ├── recognizer.py               # 抽象接口 FaceRecognizer
│   ├── arcface_recognizer.py       # ArcFace 实现
│   ├── enrollment.py               # 离线注册工具
│   └── greeting_manager.py         # 个性化问候语管理
│
├── vision/                         # 视觉识别模块
│   ├── __init__.py
│   ├── object_detector.py          # 物品识别器
│   ├── camera_handler.py           # 摄像头处理
│   └── multimodal_llm.py          # 多模态 LLM 接口
│
└── state_machine/
    └── machine.py                  # 集成两个识别功能

models/
└── face/
    ├── det_model.onnx              # RetinaFace 检测模型
    ├── rec_model.onnx              # ArcFace 识别模型
    ├── embeddings.npy              # 人脸特征向量 (N×512)
    └── names.json                  # ID → 姓名映射

data/
└── face/
    ├── greetings.json              # 个性化问候语配置
    └── enrollments/                # 注册时拍摄的照片

config.yaml                         # 添加 face 和 vision 配置段
```

---

## 配置文件扩展

### config.yaml 新增配置段

```yaml
# ========================================
# 人脸识别配置
# ========================================
face:
  enabled: true                     # 是否启用人脸识别
  mode: "standalone"                # "standalone"（独立监测）或 "on_demand"（按需）

  camera:
    device_id: 0                    # 摄像头设备 ID（0, 1, 2...）
    width: 640                      # 捕获分辨率宽度
    height: 480                     # 捕获分辨率高度
    fps: 5                          # 识别帧率（5 FPS 足够）

  models:
    det_model: "./models/face/det_model.onnx"      # RetinaFace 模型
    rec_model: "./models/face/rec_model.onnx"      # ArcFace 模型
    embeddings: "./models/face/embeddings.npy"     # 人脸特征向量
    names: "./models/face/names.json"              # 姓名映射

  recognition:
    similarity_threshold: 0.6       # 相似度阈值（0.5-0.7）
    detection_confidence: 0.8       # 检测置信度
    max_faces: 3                    # 单帧最多识别几个人脸

  greeting:
    enabled: true                   # 是否启用问候
    cooldown: 300                   # 问候冷却时间（秒，5分钟）
    default_greeting: "你好，欢迎回家！"  # 陌生人/未识别时的问候

  # 个性化问候语示例（实际存储在 greetings.json）
  greetings:
    "张三": "张三，欢迎回家！今天辛苦了"
    "李四": "李四，你回来啦！晚上想吃什么？"
    "王五": "主人好！胡桃已经准备好了"

# ========================================
# 物品识别配置
# ========================================
vision:
  enabled: true                     # 是否启用物品识别

  camera:
    device_id: 0                    # 复用人脸识别摄像头
    width: 1280                     # 拍照分辨率（更高，便于识别细节）
    height: 720

  llm:
    provider: "qwen"                # "qwen" / "openai" / "anthropic"
    model: "qwen-vl-max"            # 千问 VL 模型

    # 千问 VL 配置
    qwen:
      api_key: "${DASHSCOPE_API_KEY}"  # 复用已有环境变量
      endpoint: "https://dashscope.aliyuncs.com/compatible-mode/v1"

    # OpenAI GPT-4V 配置（备选）
    openai:
      api_key: "${OPENAI_API_KEY}"
      model: "gpt-4-vision-preview"
      endpoint: "https://api.openai.com/v1"

  recognition:
    max_image_size: 2048            # 图片最大边长（压缩以节省 token）
    prompt_template: "请仔细观察这张图片，识别图片中的物品。请用简洁的语言描述这是什么物品，以及它的主要特征。"  # 默认提示词
    temperature: 0.3                # 生成温度（低温度 = 更确定性）

  trigger_phrases:                  # 触发短语
    - "这是什么"
    - "拍照识别"
    - "帮我看看"
    - "识别物品"
```

---

## 实现流程（4 阶段）

### Stage 1 — 验证摄像头

```python
import cv2

# 测试摄像头
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

if cap.isOpened():
    ret, frame = cap.read()
    if ret:
        print("✅ 摄像头正常")
        cv2.imwrite('test_camera.jpg', frame)
    else:
        print("❌ 无法读取帧")
else:
    print("❌ 摄像头未打开")

cap.release()
```

**设备 ID 测试**:
- USB 摄像头通常是 `/dev/video0`
- 如有多个摄像头，尝试 0, 1, 2...

---

### Stage 2 — 人脸注册（离线脚本）

**流程**:
1. 拍照 → 检测人脸 → 裁剪对齐
2. 提取 512-d embedding
3. 每人 3-5 张，取均值（抗噪）
4. 存储 embeddings.npy + names.json

**注册工具**: `python src/face/enrollment.py`

```bash
# 交互式注册
python src/face/enrollment.py

# 命令行参数
python src/face/enrollment.py --name "张三" --photos 5
```

**输出文件**:
```json
// models/face/names.json
{
  "0": "张三",
  "1": "李四",
  "2": "王五"
}
```

```python
# models/face/embeddings.npy
# Shape: (N, 512) - N 个人，每人 512 维特征向量
```

---

### Stage 3 — 人脸识别模块（实时）

**核心逻辑**:
```
捕获帧 → 缩放 → RetinaFace 检测（bbox + landmarks）
       → 裁剪对齐 → ArcFace 提取 embedding
       → cosine_similarity vs 存储向量
       → 最大相似度 > 阈值 → 返回姓名
```

**伪代码**:
```python
def recognize_face(frame):
    # 1. 检测人脸
    faces = detector.detect(frame, confidence=0.8)

    # 2. 提取特征
    for face in faces:
        aligned = align_face(frame, face.landmarks)
        embedding = recognizer.extract(aligned)  # 512-d vector

        # 3. 匹配
        similarities = cosine_similarity(embedding, stored_embeddings)
        max_sim = np.max(similarities)

        if max_sim > threshold:
            name = names[np.argmax(similarities)]
        else:
            name = "Unknown"

        return name, max_sim
```

**匹配阈值调优**:
- 0.5-0.7 之间，根据实际效果调整
- 阈值越高，误识率越低，但召回率也会降低

---

### Stage 4 — 物品识别模块

**触发流程**:
```
用户唤醒 → 说"这是什么"
  → 摄像头拍照（高分辨率）
  → Base64 编码
  → 调用多模态 LLM API
  → 解析返回结果
  → TTS 语音播报
```

**实现示例**:
```python
import cv2
import base64
from openai import OpenAI

def capture_photo(device_id=0):
    """拍摄高分辨率照片"""
    cap = cv2.VideoCapture(device_id)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

    ret, frame = cap.read()
    cap.release()

    if not ret:
        raise Exception("拍照失败")

    return frame

def encode_image_to_base64(frame, format='.jpg'):
    """编码图像为 Base64"""
    _, buffer = cv2.imencode(format, frame)
    return base64.b64encode(buffer).decode('utf-8')

def recognize_object_with_qwen(base64_image, prompt="请识别图片中的物品"):
    """使用千问 VL 识别物品"""
    from dashscope import MultiModalConversation

    response = MultiModalConversation.call(
        model='qwen-vl-max',
        messages=[{
            'role': 'user',
            'content': [
                {'image': base64_image},
                {'text': prompt}
            ]
        }]
    )

    return response['output']['choices'][0]['message']['content'][0]['text']

# 完整流程
frame = capture_photo()
base64_img = encode_image_to_base64(frame)
result = recognize_object_with_qwen(base64_img)
print(f"识别结果: {result}")
# → "这是一台苹果 MacBook Pro 笔记本电脑，银色外观"
```

---

## 集成到状态机

### 人脸识别集成

**独立监测模式**（`mode: standalone`）:
```python
class StateMachine:
    def __init__(self, config):
        # ...

        # 人脸识别器（独立模式）
        face_config = config.get("face", {})
        if face_config.get("enabled") and face_config.get("mode") == "standalone":
            from ..face.arcface_recognizer import ArcFaceRecognizer
            self._face_recognizer = ArcFaceRecognizer(face_config)
            self._face_last_greeted = {}  # 记录上次问候时间
        else:
            self._face_recognizer = None

    def _update_idle(self):
        """IDLE 状态：监测唤醒词 + 人脸识别"""
        # 原有唤醒词检测逻辑...

        # 人脸识别（独立模式）
        if self._face_recognizer:
            self._check_face_recognition()

    def _check_face_recognition(self):
        """检查是否识别到人脸"""
        frame = self._camera_handler.capture_frame()
        names = self._face_recognizer.recognize(frame)

        for name, confidence in names:
            # 检查冷却时间
            last_greeted = self._face_last_greeted.get(name, 0)
            if time.time() - last_greeted > self._face_cooldown:
                # 播放个性化问候
                greeting = self._get_greeting(name)
                self._play_tts(greeting)
                self._face_last_greeted[name] = time.time()

                logger.info(f"✅ 识别到 {name}，播放问候: {greeting}")
```

### 物品识别集成

**意图检测**:
```python
def _check_vision_intent(self, text: str) -> Optional[str]:
    """检测是否为物品识别意图"""
    trigger_phrases = self._config.get("vision", {}).get("trigger_phrases", [])

    for phrase in trigger_phrases:
        if phrase in text:
            return phrase

    return None

# 在 _process_user_input 中添加
def _process_user_input(self):
    # ... STT 识别 ...

    user_text = self._stt_engine.transcribe(full_audio)

    # 检查物品识别意图
    vision_intent = self._check_vision_intent(user_text)
    if vision_intent:
        self._handle_object_recognition()
        return

    # 其他意图处理...
```

**物品识别处理**:
```python
def _handle_object_recognition(self):
    """处理物品识别"""
    logger.info("📷 开始物品识别...")

    try:
        # 1. 拍照
        from ..vision.camera_handler import CameraHandler
        camera = CameraHandler(self._config.get("vision.camera"))
        frame = camera.capture_photo()

        # 2. 调用多模态 LLM
        from ..vision.multimodal_llm import MultimodalLLM
        llm = MultimodalLLM(self._config.get("vision.llm"))

        result = llm.recognize_object(frame)

        # 3. 输出结果
        print("\n" + "="*60)
        print("📷 物品识别")
        print("="*60)
        print(f"  识别结果: {result}")
        print("="*60 + "\n")

        # 4. TTS 播报
        audio_data = self._tts_engine.synthesize(result)
        self._feedback_player.play_audio(audio_data)

        # 5. 返回 IDLE（或继续对话）
        self.transition_to(State.IDLE)

    except Exception as e:
        logger.error(f"物品识别失败: {e}")
        self._play_tts("抱歉，物品识别失败了")
        self.transition_to(State.IDLE)
```

---

## API 设计

### FaceRecognizer 抽象接口

```python
from abc import ABC, abstractmethod
from typing import List, Tuple
import numpy as np

class FaceRecognizer(ABC):
    """人脸识别器抽象接口"""

    @abstractmethod
    def load_models(self) -> None:
        """加载模型"""
        pass

    @abstractmethod
    def recognize(self, frame: np.ndarray) -> List[Tuple[str, float]]:
        """
        识别单帧图像中的人脸

        Args:
            frame: 图像帧 (BGR 格式)

        Returns:
            List[Tuple[str, float]]: [(姓名, 相似度), ...]
        """
        pass

    @abstractmethod
    def enroll(self, name: str, frames: List[np.ndarray]) -> bool:
        """
        注册新人脸

        Args:
            name: 姓名
            frames: 多张照片（3-5张）

        Returns:
            bool: 是否成功
        """
        pass

    @abstractmethod
    def get_embedding(self, frame: np.ndarray) -> np.ndarray:
        """
        提取人脸特征向量

        Args:
            frame: 对齐后的人脸图像

        Returns:
            np.ndarray: 512-d 特征向量
        """
        pass
```

### ObjectDetector 接口

```python
class ObjectDetector(ABC):
    """物品识别器抽象接口"""

    @abstractmethod
    def recognize(self, frame: np.ndarray, prompt: str = None) -> str:
        """
        识别图像中的物品

        Args:
            frame: 图像帧 (BGR 格式)
            prompt: 自定义提示词（可选）

        Returns:
            str: 识别结果（自然语言描述）
        """
        pass
```

---

## 需要安装的依赖

### 核心依赖
```bash
pip install opencv-python
pip install insightface
```

### 备选方案（insightface 装不上时）
如果 `insightface` 在 ARM64 上安装失败，手动处理：
1. 从 InsightFace GitHub 下载 ONNX 模型
2. 自己写预处理/后处理（标准化流程）
3. 仍使用 `onnxruntime` 推理

### 多模态 LLM SDK
```bash
# 千问 VL（已安装，复用）
pip install dashscope

# OpenAI GPT-4V（备选）
pip install openai

# Claude 3 Vision（备选）
pip install anthropic
```

---

## 个性化问候语配置

### data/face/greetings.json

```json
{
  "default": "你好，欢迎回家！",
  "greetings": {
    "张三": {
      "morning": "张三，早上好！今天又是元气满满的一天",
      "afternoon": "张三，下午好！工作辛苦了",
      "evening": "张三，晚上好！欢迎回家",
      "default": "张三，欢迎回家！今天辛苦了"
    },
    "李四": {
      "default": "李四，你回来啦！晚上想吃什么？"
    },
    "王五": {
      "default": "主人好！胡桃已经准备好了"
    }
  },
  "time_based": true,  // 是否启用基于时间的问候
  "cooldown": 300      // 冷却时间（秒）
}
```

**问候语选择逻辑**:
1. 识别到姓名 → 查询 greetings.json
2. 根据当前时间选择问候语（morning/afternoon/evening）
3. 如果没有时间相关配置，使用 default
4. 如果未找到姓名，使用 default（陌生人问候）

---

## 测试计划

### 人脸识别测试
```bash
# 1. 摄像头测试
python tests/manual/test_camera.py

# 2. 人脸注册
python src/face/enrollment.py --name "测试用户" --photos 3

# 3. 识别测试
python tests/manual/test_face_recognition.py

# 4. 问候语测试
python tests/manual/test_face_greeting.py
```

### 物品识别测试
```bash
# 1. 拍照测试
python tests/manual/test_camera_capture.py

# 2. 千问 VL 识别测试
python tests/manual/test_object_recognition.py --provider qwen

# 3. 集成测试
# 唤醒 → 说"这是什么" → 对准物品 → 验证识别结果
```

---

## 故障排查

### 摄像头问题
```bash
# 列出摄像头设备
ls /dev/video*

# 测试摄像头
ffplay /dev/video0
# 或
gst-launch-1.0 v4l2src device=/dev/video0 ! videoconvert ! autovideosink
```

### 人脸识别精度问题
- **检测不到人脸**: 调低 `detection_confidence`（如 0.5）
- **误识率过高**: 调高 `similarity_threshold`（如 0.7）
- **召回率过低**: 调低 `similarity_threshold`（如 0.5）
- **重新注册**: 确保注册照片光照、角度多样化

### 物品识别失败
- **网络问题**: 检查 API 连接（参考之前的网络错误处理）
- **图片质量**: 增加拍照分辨率（1280x720）
- **Token 限制**: 压缩图片到 2048px 以下

---

## 性能优化建议

1. **分时加载模型**:
   - 人脸识别模式：仅加载人脸模型，卸载 STT 模型
   - 对话模式：加载 STT/LLM，卸载人脸模型
   - 物品识别：临时激活，用完即释放

2. **降低识别频率**:
   - 人脸识别不需要 30 FPS，3-5 FPS 足够
   - 使用 `time.sleep()` 控制帧率

3. **图像分辨率**:
   - 人脸识别：640x480 足够
   - 物品识别：1280x720（需要更多细节）

4. **GPU 加速**（可选）:
   - 树莓派 5 **没有 GPU**，只能 CPU 推理
   - 未来可考虑 Coral TPU 加速（USB 加速棒）

---

## 未来扩展

### 功能扩展
1. **多人识别**: 同时识别多个人脸，分别问候
2. **表情识别**: 检测情绪，调整问候语
3. **年龄估计**: 老人/小孩不同的问候方式
4. **物品记忆**: 记住物品位置，"我的钥匙在哪里？"

### 模型升级
1. **更高精度模型**: 更大的 ArcFace 模型（如 ResNet100）
2. **轻量化模型**: MobileFaceNet（更快，但精度略低）
3. **多模态融合**: 人脸 + 声纹联合识别

---

## 参考资源

- **InsightFace**: https://github.com/deepinsight/insightface
- **ArcFace Paper**: https://arxiv.org/abs/1901.00236
- **千问 VL**: https://help.aliyun.com/zh/dashscope/developer-reference/quick-start
- **OpenCV ARM64**: https://opencv.org/releases/
- **ONNX Runtime**: https://onnxruntime.ai/docs/

---

## 总结

本方案在现有语音助手基础上，增加了：
1. **人脸识别**: 独立监测模式，个性化问候
2. **物品识别**: 唤醒后拍照识别，多模态 LLM 支持

**核心技术优势**:
- 复用已有 `onnxruntime`，无需额外依赖
- 分时加载模型，内存可控
- 模块化设计，易于集成和维护

**预计开发周期**:
- Stage 1-2（摄像头+注册）: 1-2 天
- Stage 3（人脸识别）: 2-3 天
- Stage 4（物品识别）: 2-3 天
- 集成测试: 1-2 天

**总计**: 约 1 周完成核心功能
