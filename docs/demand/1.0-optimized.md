# 树莓派 5 本地语音助手系统需求文档 (v1.1)

**版本**: 1.1 (优化版)
**最后更新**: 2026年1月21日
**状态**: ✅ 完整整合 + 架构兼容性说明

---

## 📋 文档变更记录

| 版本 | 日期 | 变更内容 | 作者 |
|------|------|----------|------|
| 1.0 | 2026-01-20 | 初始版本 | - |
| 1.1 | 2026-01-21 | 修复格式问题,补充架构兼容性,完善需求细节 | Claude |

---

## 一、项目目标

在 **树莓派 5 (8GB RAM)** + **ReSpeaker 4 Mic Array** 硬件平台上,构建一个高鲁棒性、远场中文语音交互系统。系统支持:

- ✅ **离线唤醒词检测** - 基于 OpenWakeWord,低延迟低功耗
- ✅ **离线高精度中文语音识别** (STT) - FunASR SenseVoiceSmall
- ✅ **联网调用大语言模型** (LLM) - 阿里云千问 API 生成智能回复
- ✅ **本地高质量中文语音合成** (TTS) - CosyVoice 2.0
- ✅ **自然多样的唤醒反馈** - 随机回复语 + 时间问候

**用户体验目标**: 实现"说唤醒词 → 听到回应 → 下达指令 → 获得语音回答"的完整闭环,适用于智能家居、个人助理等场景。

---

## 二、硬件环境

| 组件 | 型号/规格 | 说明 |
|------|-----------|------|
| **主控** | Raspberry Pi 5 (8GB RAM) | Raspberry Pi OS 64-bit (Bookworm) |
| **麦克风阵列** | Seeed Studio ReSpeaker 4 Mic Array | 4麦克风圆形阵列,硬件级波束成形 + 声源定位(DOA) |
| **扬声器** | ReSpeaker 板载 3.5mm 输出 | 音频输出通过 3.5mm 接口 |
| **存储** | 128GB microSD U3 (推荐) | 模型文件 + 系统 + 日志 |
| **网络** | Wi-Fi 6 / Gigabit Ethernet | 仅用于调用千问 API |

### 关键优势
- ✅ 支持 **3~5 米远场拾音**
- ✅ 内置 XMOS 处理器输出**波束成形后单通道音频**,显著提升信噪比
- ✅ 硬件级 DOA (声源定位),预留扩展

---

## 三、平台架构兼容性 ⚠️

### 开发 vs 生产环境

| 环境 | 架构 | 说明 |
|------|------|------|
| **开发环境** | amd64 (x86_64) | 本地开发机器,用于快速迭代和测试 |
| **生产环境** | arm64 | 树莓派5,实际部署环境 |

### 跨平台兼容性要求

#### 1. 依赖库兼容性
- ✅ 所有 Python 依赖必须支持 **arm64** 架构
- ✅ 深度学习框架使用 **CPU 版本** 或兼容 ARM NEON 指令集
- ⚠️ 避免使用需要特定架构优化的库(如某些预编译二进制依赖)

#### 2. 推荐依赖
```python
# 示例:使用纯Python或arm64支持的库
torch>=2.0.0  # 官方提供 arm64 轮子
funasr>=1.0.0  # 纯Python或arm64支持
openwakeword>=1.0.0  # 纯Python实现
pyaudio  # 需要系统级PortAudio支持
```

#### 3. 模型文件兼容性
- ✅ FunASR 和 CosyVoice 模型为**跨平台格式**(PyTorch .pt/.pth)
- ✅ 模型文件在两架构间可通用
- ⚠️ 首次运行需在目标架构上下载模型

#### 4. 测试策略
- 🔧 **单元测试**: 可在 amd64 开发环境运行
- 🎯 **集成测试**: 建议在 arm64 环境或容器中验证
- ⚡ **性能测试**: 必须在树莓派5真机上测试

#### 5. 部署流程
```bash
# 开发环境 (amd64)
# 1. 编写和测试代码逻辑
# 2. 不依赖硬件的模块测试

# 生产环境 (arm64)
# 3. SSH 登录树莓派
# 4. 拉取代码
# 5. pip install -r requirements.txt (arm64版本依赖)
# 6. 验证硬件连接
# 7. 运行集成测试
```

---

## 四、软件架构

### 数据流图

```
[远场语音输入]
       ↓
[ReSpeaker 4-Mic → XMOS 波束成形] → 单通道 16kHz 音频流
       ↓
[唤醒检测] → OpenWakeWord (离线)
       ↓ (检测到唤醒词)
[Wake-up Response Manager] → 随机选择唤醒回复 → Piper TTS → 播放
       ↓
[语音录制 + VAD] → FunASR 内置 VAD 切分
       ↓
[语音识别 STT] → FunASR SenseVoiceSmall (离线)
       ↓ (输出文本)
[语义理解 & 对话生成] → 阿里云 Qwen API (需联网)
       ↓ (返回文本)
[语音合成 TTS] → CosyVoice 2.0 (离线)
       ↓
[音频播放] → ReSpeaker 3.5mm 输出
```

### 模块依赖关系

```
┌─────────────────────────────────────────────┐
│             Main State Machine              │
│  (IDLE → WAKEUP → LISTENING → ...)          │
└───────────┬─────────────────────────────────┘
            │
    ┌───────┴───────┬─────────────┬────────────┐
    ↓               ↓             ↓            ↓
┌────────┐    ┌─────────┐  ┌─────────┐  ┌─────────┐
│WakeWord│    │   STT   │  │   LLM   │  │   TTS   │
└────────┘    └─────────┘  └─────────┘  └─────────┘
    ↓               ↓             ↓            ↓
┌────────┐    ┌─────────┐  ┌─────────┐  ┌─────────┐
│Config  │    │ FunASR  │  │ Qwen    │  │CosyVoice│
└────────┘    └─────────┘  └─────────┘  └─────────┘
```

---

## 五、核心模块详细需求

### 1. 唤醒词检测 (Wake Word Detection)

| 属性 | 要求 |
|------|------|
| **方案** | OpenWakeWord |
| **模型** | 自定义中文唤醒词 (如 "胡桃", "小智小智") |
| **离线能力** | ✅ 完全离线 |
| **性能要求** | 实时监听, CPU 占用 **< 5%** |
| **唤醒延迟** | **< 300ms** (从说出唤醒词到触发) |
| **误报率** | **< 1次/小时** (安静环境) |
| **模型格式** | `.ppn` 文件,需自行训练 |

**训练资源**:
- 官方文档: https://github.com/dscripka/openWakeWord/wiki

**输出**: `bool` (是否检测到唤醒词)

---

### 2. 语音识别 (STT)

| 属性 | 要求 |
|------|------|
| **方案** | FunASR |
| **模型** | `iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch` |
| **离线能力** | ✅ 完全离线 |
| **特性** | - 自动 VAD 切分语音段<br>- 支持标点恢复<br>- 实时因子 (RTF) < 0.1<br>- 支持中断 (最长10s) |
| **字准确率** | **> 95%** (清晰发音,安静环境) |
| **处理延迟** | **< 1s** (10秒语音) |

**API 要求**:
```python
# 伪代码示例
def transcribe(audio_array: np.ndarray) -> str:
    """
    输入: numpy array (16kHz, 16bit, 单通道)
    输出: 识别文本 (str)
    """
```

**首次运行**: 需联网下载模型 (~200MB)

---

### 3. 语言模型 (LLM)

| 属性 | 要求 |
|------|------|
| **方案** | 阿里云 Qwen (千问) API |
| **模型** | `qwen-max` 或 `qwen-plus` |
| **离线能力** | ❌ 需联网 |
| **API Key** | 通过环境变量 `DASHSCOPE_API_KEY` 注入 |
| **超时时间** | **10 秒** |
| **失败处理** | 播放错误提示音,返回 IDLE 状态 |
| **上下文管理** | 预留多轮对话接口 (v1.2) |

**API 要求**:
```python
# 伪代码示例
def generate_response(user_input: str, history: List[Dict] = None) -> str:
    """
    输入:
        - user_input: 用户文本
        - history: 对话历史 (可选,预留)
    输出: 回复文本 (str)
    异常: 处理网络超时,API错误等
    """
```

---

### 4. 语音合成 (TTS)

| 属性 | 要求 |
|------|------|
| **方案** | CosyVoice 2.0 |
| **模型** | `iic/CosyVoice-300M` |
| **离线能力** | ✅ 完全离线 (首次需下载) |
| **音色** | 中文女声 (默认),情感自然 |
| **合成延迟** | **< 2s** (≤20字) |
| **输出格式** | 16kHz, 16bit PCM (numpy array) |
| **缓存策略** | 相同文本复用音频文件,减少重复合成 |

**API 要求**:
```python
# 伪代码示例
def synthesize(text: str) -> np.ndarray:
    """
    输入: 待合成文本 (str)
    输出: 音频流 (numpy array, 16kHz, 16bit)
    """
```

**模型大小**: ~300MB

---

### 5. 音频 I/O

| 属性 | 要求 |
|------|------|
| **输入设备** | ReSpeaker 4-Mic (BF 通道, 16kHz, 单通道) |
| **输出设备** | 3.5mm 接口 (通过 pyaudio 播放) |
| **驱动** | 官方 seeed-voicecard 驱动 |
| **采样率** | 16000 Hz |
| **位深** | 16-bit |
| **通道** | 单声道 (Mono) |

**验证命令**:
```bash
# 查看 ReSpeaker 设备
arecord -L | grep seeed

# 测试录音
arecord -D seeed-4mic-voicecard -f S16_LE -r 16000 -c 1 test.wav

# 测试播放
aplay -D plughw:1,0 test.wav
```

---

## 六、状态机设计

### 状态定义

| 状态 | 描述 | 触发条件 | 动作 |
|------|------|----------|------|
| **IDLE** | 监听唤醒词 | 系统启动 / 从 ERROR 恢复 | 运行 OpenWakeWord 循环 |
| **WAKEUP** | 唤醒成功 | OpenWakeWord 检测到关键词 | 1. 选择随机唤醒回复语<br>2. 调用 CosyVoice TTS<br>3. 播放音频<br>4. 转入 LISTENING |
| **LISTENING** | 录制用户语音 | VAD 检测到语音开始 | 1. 开始录音<br>2. 监听 VAD 结束<br>3. 转入 PROCESSING |
| **PROCESSING** | 正在处理 | VAD 检测到静音 | 1. 调用 FunASR STT<br>2. 调用 Qwen LLM<br>3. 调用 CosyVoice TTS<br>4. 转入 SPEAKING |
| **SPEAKING** | 正在播报 | TTS 音频生成完成 | 1. 播放回复语音<br>2. 播放结束转入 IDLE |
| **ERROR** | 异常处理 | 任一模块失败 / 超时 | 1. 播放错误提示<br>2. 记录日志<br>3. 返回 IDLE |

### 状态转换图

```
    ┌─────────┐
    │  IDLE   │ ◄─────────────────────────────────────┐
    └────┬────┘                                       │
         │ 检测到唤醒词                                │
         ▼                                             │
    ┌─────────┐                                       │
    │ WAKEUP  │                                       │
    └────┬────┘                                       │
         │ 播放唤醒回复完成                            │
         ▼                                             │
    ┌───────────┐                                     │
    │ LISTENING │                                     │
    └─────┬─────┘                                     │
          │ VAD 检测到语音结束                        │
          ▼                                           │
    ┌─────────────┐    处理失败/超时                  │
    │ PROCESSING  ├─────────────────┐                │
    └──────┬──────┘                 │                │
           │ 处理成功               │                │
           ▼                        │                │
    ┌─────────┐                    ▼                │
    │ SPEAKING │              ┌─────────┐            │
    └────┬────┘              │  ERROR  │            │
         │ 播放完成          └────┬────┘            │
         └────────────────────────┘                 │
                                               ┌────┴────┐
                                               │  IDLE   │
                                               └─────────┘
```

### 超时机制

| 状态 | 超时时间 | 超时后动作 |
|------|----------|------------|
| LISTENING | 10秒 | 未检测到有效语音,返回 IDLE |
| PROCESSING | 15秒 | 调用失败,播放错误提示,返回 IDLE |
| ERROR | 无 | 自动返回 IDLE |

---

## 七、配置文件

### config.yaml 完整示例

```yaml
# ========================================
# 硬件音频配置
# ========================================
audio:
  input_device: "seeed-4mic-voicecard"  # ReSpeaker 4-Mic BF 通道
  output_device: 1                      # 3.5mm 接口 (pyaudio device index)
  sample_rate: 16000                    # 采样率 16kHz
  channels: 1                           # 单声道
  chunk_size: 512                       # 音频块大小
  format: "int16"                       # 16-bit PCM

# ========================================
# 唤醒词配置
# ========================================
wakeword:
  engine: "openwakeword"
  keyword: "paimon_paimon_zh.ppn"       # 自定义模型路径
  threshold: 0.5                        # 检测阈值 (0-1)
  model_dir: "./models/openwakeword"        # 模型存储目录

# ========================================
# 唤醒反馈配置
# ========================================
wake_feedback:
  enabled: true
  use_beep: false                       # 是否使用蜂鸣声(简单模式)

  # 通用唤醒回复库
  responses:
    general:
      - "我在呢~"
      - "你好呀!"
      - "请说~"
      - "胡桃听着呢!"
      - "有什么我可以帮你的吗?"
      - "嗯? 我在!"
      - "随时为您效劳!"
      - "说吧,我准备好了!"
      - "很高兴为您服务!"
      - "听到了,请告诉我您的需求。"
      - "准备就绪,等待您的指令。"
      - "您好,愿为您效劳。"
      - "发现您了,准备好聆听。"
      - "在这里,等您说话。"
      - "期待您的问题或命令。"

    # 时间相关问候
    morning:
      - "早上好!今天有什么计划?"
      - "早安!愿您今天充满活力!"
    afternoon:
      - "下午好,需要什么帮助吗?"
      - "下午茶时间,有什么吩咐?"
    evening:
      - "晚上好,欢迎回来!"
      - "辛苦了一天,休息一下吧!"

  # TTS 音色配置(用于唤醒回复)
  tts:
    speaker: "中文女声"
    speed: 1.0                          # 语速倍率

# ========================================
# LLM 配置
# ========================================
llm:
  provider: "qwen"
  model: "qwen-max"                     # 或 qwen-plus, qwen-turbo
  api_key_env: "DASHSCOPE_API_KEY"      # 环境变量名
  timeout: 10                           # 超时时间(秒)
  max_retries: 2                        # 失败重试次数

  # 系统提示词 (可配置)
  system_prompt: |
    你是一个智能语音助手,名叫"胡桃"。
    请用简洁、友好的语气回答用户问题。
    回复尽量口语化,避免过长的回答，最好不超过50个字。

# ========================================
# TTS 配置
# ========================================
tts:
  engine: "cosyvoice"
  model: "iic/CosyVoice-300M"
  model_dir: "./models/cosyvoice"       # 模型存储目录

  speaker: "中文女声"
  speed: 1.0
  sample_rate: 16000

  # 缓存配置
  cache_enabled: true
  cache_dir: "./cache/tts"

# ========================================
# STT 配置
# ========================================
stt:
  engine: "funasr"
  model: "iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
  model_dir: "./models/funasr"

  # VAD 配置
  vad_enabled: true
  vad_max_speech_duration_s: 10         # 最长录音时长(秒)
  vad_max_pause_s: 1.5                  # 静音多久结束录音(秒)

# ========================================
# 日志配置
# ========================================
logging:
  level: "INFO"                         # DEBUG, INFO, WARNING, ERROR
  file: "./logs/assistant.log"
  max_size_mb: 100
  backup_count: 3

# ========================================
# 系统配置
# ========================================
system:
  # 性能监控
  monitor_performance: true

  # 资源限制
  max_memory_mb: 3500                   # 最大内存使用
  max_cpu_percent: 80                   # 最大CPU使用率

  # 错误处理
  auto_recovery: true                   # 自动从错误恢复
  error_sound: "./assets/error.wav"     # 错误提示音
```

---

## 八、非功能性需求

| 类别 | 指标 | 测试方法 |
|------|------|----------|
| **离线能力** | 除 LLM 外,所有模块完全离线 | 断网测试,验证唤醒/STT/TTS |
| **远场性能** | 3 米内清晰唤醒与识别 | 安静环境,距离测试 |
| **抗噪能力** | 50dB 背景噪声下仍可工作 | 播放白噪声,测试唤醒率 |
| **响应延迟** | 从说话到 TTS 播放 ≤ 3 秒 (含网络) | 端到端计时测试 |
| **资源占用** | 内存 < 3.5GB, CPU 平均 < 60% | `top`, `htop` 监控 |
| **隐私安全** | 语音数据不上传,仅文本发往千问 | 网络抓包验证 |
| **可维护性** | 模块解耦,配置文件化 (YAML) | 代码审查 |
| **日志** | 支持 DEBUG/INFO 日志输出 | 运行时日志验证 |
| **稳定性** | 连续运行 24 小时无崩溃 | 压力测试 |

---

## 九、错误处理策略

### 错误分类

| 错误类型 | 示例 | 处理策略 |
|----------|------|----------|
| **硬件错误** | ReSpeaker 未连接 | 1. 记录错误日志<br>2. 播放错误提示音<br>3. 返回 IDLE<br>4. 等待用户重启 |
| **网络错误** | 千问 API 超时 | 1. 重试 2 次<br>2. 仍失败则播放"网络连接异常"<br>3. 返回 IDLE |
| **STT 错误** | 识别失败或结果为空 | 1. 播放"抱歉,我没听清楚"<br>2. 返回 IDLE |
| **TTS 错误** | 合成失败 | 1. 记录日志<br>2. 播放备用蜂鸣声<br>3. 返回 IDLE |
| **模型加载失败** | 模型文件缺失 | 1. 记录严重错误<br>2. 播放"系统初始化失败"<br>3. 退出程序 |

### 错误提示语音库

```yaml
error_messages:
  network_error: "抱歉,网络连接异常,请稍后再试。"
  stt_error: "抱歉,我没听清楚,能再说一遍吗?"
  tts_error: "[蜂鸣声]"  # 或 "系统语音合成异常"
  system_error: "系统异常,请联系管理员。"
  timeout: "抱歉,响应超时了。"
```

---

## 十、性能测试基准

### 测试场景

| 场景 | 预期结果 | 测试工具 |
|------|----------|----------|
| **唤醒测试** | 3米距离,10次唤醒,成功 ≥ 8次 | 人工测试 |
| **STT 准确率** | 清晰朗读100句,字准确率 > 95% | 标准测试集 |
| **端到端延迟** | 从说话到 TTS 播放 ≤ 3秒 | 计时脚本 |
| **内存占用** | 运行 1 小时,内存 < 3.5GB | `free -h` |
| **CPU 占用** | IDLE 状态 < 10%, PROCESSING < 80% | `top` |
| **稳定性** | 连续运行 24 小时无崩溃 | 长时间测试 |

### 基准命令

```bash
# 监控资源
while true; do ps aux | grep python; sleep 5; done

# 测试延迟
time python main.py  # 手动触发完整流程

# 压力测试
for i in {1..100}; do
  echo "测试轮次 $i"
  # 触发唤醒 → STT → LLM → TTS
done
```

---

## 十一、部署流程

### 树莓派环境准备

```bash
# 1. 更新系统
sudo apt update && sudo apt upgrade -y

# 2. 安装依赖
sudo apt install -y python3 python3-pip python3-venv portaudio19-dev

# 3. 安装 ReSpeaker 驱动
git clone https://github.com/seeed-studio/seeed-voicecard.git
cd seeed-voicecard
sudo ./install.sh
sudo reboot

# 4. 验证音频设备
arecord -L | grep seeed

# 5. 克隆项目
git clone <repo_url>
cd home_pi

# 6. 创建虚拟环境
python3 -m venv .venv
source .venv/bin/activate

# 7. 安装依赖 (arm64版本)
pip install -r requirements.txt

# 8. 配置环境变量
export DASHSCOPE_API_KEY="your_api_key_here"

# 9. 配置文件
cp config.example.yaml config.yaml
vim config.yaml

# 10. 首次运行 (下载模型)
python main.py

# 11. 设置开机自启 (可选)
sudo cp scripts/voice-assistant.service /etc/systemd/system/
sudo systemctl enable voice-assistant
sudo systemctl start voice-assistant
```

---

## 十二、待办事项 (TODO)

### 🔴 高优先级 (核心功能)

- [ ] **1.1** 安装 ReSpeaker 4-Mic 驱动并验证 BF 音频流
  - 验证命令: `arecord -D seeed-4mic-voicecard -f S16_LE -r 16000 -c 1 test.wav`
- [ ] **1.2** 实现基础状态机框架 (Python)
  - 定义状态枚举和转换逻辑
  - 实现状态机主循环
- [ ] **1.3** 集成 OpenWakeWord 唤醒词检测
  - 训练或下载中文唤醒词模型
  - 实现 IDLE → WAKEUP 转换
- [ ] **1.4** 集成 FunASR STT 模块
  - 下载 SenseVoiceSmall 模型
  - 实现 LISTENING → PROCESSING 转换
- [ ] **1.5** 集成 CosyVoice TTS 模块
  - 下载 CosyVoice-300M 模型
  - 实现 PROCESSING → SPEAKING 转换
- [ ] **1.6** 集成千问 LLM API
  - 实现对话生成逻辑
  - 添加超时和错误处理

### 🟡 中优先级 (用户体验)

- [ ] **2.1** 集成唤醒反馈管理器
  - 实现随机回复库
  - 添加时间问候语 (早/中/晚)
- [ ] **2.2** 实现配置文件管理
  - 创建 config.yaml
  - 实现配置加载和验证
- [ ] **2.3** 添加日志系统
  - 结构化日志输出
  - 文件轮转机制
- [ ] **2.4** 优化 TTS 缓存策略
  - 相同文本复用音频文件
  - 实现 LRU 缓存

### 🟢 低优先级 (优化和扩展)

- [ ] **3.1** 添加异常处理与超时机制
  - 实现各状态的超时返回
  - 错误提示语音库
- [ ] **3.2** 性能优化
  - 降低 IDLE 状态 CPU 占用
  - 优化内存使用
- [ ] **3.3** 单元测试覆盖
  - 测试状态转换逻辑
  - Mock 硬件依赖
- [ ] **3.4** DOA 声源定位 (预留)
- [ ] **3.5** 多轮对话管理 (预留)
- [ ] **3.6** 技能插件系统 (预留)

---

## 十三、参考资源

### 官方文档
- [ReSpeaker 4 Mic Array Wiki](https://wiki.seeedstudio.com/ReSpeaker_4_Mic_Array_for_Raspberry_Pi/)
- [OpenWakeWord GitHub](https://github.com/dscripka/openWakeWord)
- [FunASR GitHub](https://github.com/alibaba-damo-academy/FunASR)
- [CosyVoice GitHub](https://github.com/FunAudioLLM/CosyVoice)
- [千问 API 文档](https://help.aliyun.com/zh/dashscope/developer-reference/)

### 技术博客
- OpenWakeWord 模型训练教程
- FunASR 部署最佳实践
- 树莓派音频调优指南

### 社区
- [ReSpeaker 论坛](https://forum.seeedstudio.com/)
- [FunASR Issues](https://github.com/alibaba-damo-academy/FunASR/issues)

---

## 十四、附录

### 磁盘空间估算

| 组件 | 大小 | 说明 |
|------|------|------|
| Raspberry Pi OS | ~3GB | 基础系统 |
| Python 环境 | ~500MB | .venv |
| FunASR 模型 | ~200MB | SenseVoiceSmall |
| CosyVoice 模型 | ~300MB | CosyVoice-300M |
| OpenWakeWord 模型 | ~5MB | 自定义 .ppn |
| 日志和缓存 | ~100MB (可配置) | 日志轮转 |
| **总计** | **~4.2GB** | 推荐使用 ≥ 32GB SD卡 |

### 环境变量模板

```bash
# .env.example
DASHSCOPE_API_KEY=your_api_key_here

# 可选
LOG_LEVEL=INFO
MODEL_CACHE_DIR=./models
```

### systemd 服务配置 (可选)

```ini
# /etc/systemd/system/voice-assistant.service
[Unit]
Description=Voice Assistant Service
After=network.target sound.target

[Service]
Type=simple
User=pi
WorkingDirectory=/home/pi/home_pi
Environment="DASHSCOPE_API_KEY=your_api_key"
ExecStart=/home/pi/home_pi/.venv/bin/python /home/pi/home_pi/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

---

**备注**: 本系统不依赖任何第三方云语音服务,最大程度保障隐私、可控性与离线可用性。
