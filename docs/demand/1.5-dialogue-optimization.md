# Phase 1.5: 智能对话交互优化需求文档

**版本**: 1.0
**日期**: 2026-01-23
**优先级**: P1
**状态**: 需求定义中
**参考**: 小米小爱同学对话交互设计

---

## 文档变更记录

| 版本 | 日期 | 变更内容 | 作者 |
|------|------|----------|------|
| 1.0 | 2026-01-23 | 初始版本 | Claude |

---

## 1. 背景：小爱同学对话功能分析

### 1.1 小爱同学的核心对话特性

| 特性 | 描述 | 用户价值 |
|------|------|----------|
| **多轮对话** | 支持连续对话，自动维护上下文 | 无需重复唤醒，自然流畅 |
| **智能打断** | 播放中可直接说话打断并下达新指令 | 快速纠错，提升效率 |
| **技能扩展** | 智能家居控制、音乐播放、查询等 | 实用功能，提升粘性 |
| **情感化回复** | 语气自然，有拟人化特征 | 亲和力强，用户体验好 |
| **个性化** | 记住用户偏好，定制化回复 | 贴近用户，提升满意度 |

### 1.2 当前系统 (Phase 1.4) 对比

| 功能 | 小爱同学 | 当前系统 | 差距 |
|------|----------|----------|------|
| 多轮对话 | ✅ 优秀 | ✅ 基础支持 | 需增强上下文管理 |
| 智能打断 | ✅ 支持 | ❌ 不支持 | **高优先级** |
| 技能系统 | ✅ 丰富 | ❌ 无 | 中优先级 |
| 情感化回复 | ✅ 优秀 | ⚠️ 基础支持 | 低优先级 |
| 个性化 | ✅ 支持 | ❌ 不支持 | 低优先级 |

### 1.3 用户痛点（基于小爱对比）

| 痛点 | 描述 | 优先级 |
|------|------|----------|
| **无法打断** | TTS 播放时无法停止，只能等待说完 | P0 |
| **功能单一** | 只能问答，不能控制音乐或家居 | P1 |
| **回复机械** | 提示语固定，缺少人情味 | P2 |

### 1.4 设计说明

⚠️ **免唤醒指令暂不实现**

考虑到系统稳定性和用户习惯，**Phase 1.5 不实现免唤醒指令功能**。所有操作都需要通过唤醒词触发，保持与 Phase 1.4 的一致性。这有助于：
- 避免误触发
- 保持交互逻辑清晰
- 降低实现复杂度

**说明**：用户明确表示"现在先都通过唤醒词来指令"，因此所有指令都必须先唤醒，然后再说出指令内容。

---

## 2. 需求概述

### 2.1 核心目标

借鉴小爱同学的优秀交互设计，在 **Phase 1.4 基础上** 增强：

1. **智能打断**：TTS 播放时检测到语音立即停止
2. **上下文增强**：优化多轮对话的上下文管理
3. **技能系统框架**：为智能家居控制等预留扩展接口

### 2.2 设计原则

1. **最小改动**：在现有架构上增强，不破坏已有功能
2. **渐进实现**：分阶段落地，核心功能优先
3. **资源友好**：不显著增加 CPU/内存占用
4. **用户导向**：以提升用户体验为核心目标

### 2.3 功能优先级

| 功能 | 优先级 | 复杂度 | 说明 |
|------|--------|--------|------|
| **智能打断** | P0 | 中 | 提升 TTS 播放时的用户体验 |
| **上下文增强** | P1 | 低 | 改进多轮对话的流畅度 |
| **技能系统框架** | P1 | 中 | 为功能扩展预留接口 |
| **情感化回复** | P2 | 低 | 提升亲和力（改进提示语） |
| **个性化** | P2 | 高 | 需要用户系统支持 |

---

## 3. 详细需求规格

### 3.1 智能打断（P0）

#### 功能描述

在 TTS 播放回复时，如果检测到用户说话（语音活动），立即停止播放并根据输入内容做出反应。

#### 交互流程

```
正常对话流程：
用户: "今天天气怎么样" → LLM 回复 → TTS 播放中

打断流程：
用户: "今天天气怎么样" → LLM 回复 → TTS 播放中
用户: （打断）"停止" → 立即停止 TTS
用户: "明天呢" → 继续对话

智能判断流程：
TTS 播放中 → 检测到语音 → 停止播放
  ↓
判断语音内容：
  - "停止"/"算了" → 取消当前回复，返回 LISTENING
  - "再大一点" → 调整音量（如支持），返回 LISTENING
  - 其他内容 → 视为新的指令，进行 STT + LLM
```

#### 实现方案

```python
class SpeakingState:
    """SPEAKING 状态增强（支持打断）"""

    def _update_speaking(self) -> None:
        """
        SPEAKING 状态更新：播放 TTS 回复（支持打断）

        Phase 1.5: 添加智能打断功能
        """
        # 检测 TTS 是否播放完成
        if not self._feedback_player.is_playing():
            # 播放完成，进入下一轮
            self._handle_playback_complete()
            return

        # Phase 1.5 新增：检测打断
        # 在播放过程中持续检测语音活动
        # 为了不阻塞主循环，每 N 帧检测一次
        if hasattr(self, '_interrupt_check_counter'):
            self._interrupt_check_counter += 1
        else:
            self._interrupt_check_counter = 0

        # 每 10 帧（约 300ms）检测一次
        interrupt_check_interval = 10
        if self._interrupt_check_counter >= interrupt_check_interval:
            self._interrupt_check_counter = 0

            # 快速检测是否有语音输入
            audio_frame = self._audio_input.read_chunk()
            has_speech = self._quick_speech_detection(audio_frame)

            if has_speech:
                # 检测到语音，停止播放
                logger.info("检测到用户语音，停止 TTS 播放")
                print(f"\n🛑 检测到打断，停止播放\n")

                # 停止 TTS 播放
                self._feedback_player.stop()

                # 录制用户在打断时的语音（缓冲）
                self._record_interrupt_audio()

                # 进入 LISTENING 状态，等待完整输入
                self.transition_to(State.LISTENING)

    def _quick_speech_detection(self, audio_frame: np.ndarray) -> bool:
        """
        快速语音检测（用于打断检测）

        Args:
            audio_frame: 音频帧

        Returns:
            bool: 是否检测到语音
        """
        # 使用自适应 VAD 阈值
        if self._adaptive_vad:
            threshold = self._adaptive_vad.get_adaptive_threshold()
        else:
            threshold = 0.04  # 默认阈值

        # 计算 RMS 能量
        audio_float = audio_frame.astype(float) / 32768.0
        energy = np.sqrt(np.mean(audio_float ** 2))

        # 简单判断：能量超过阈值且持续几帧
        return energy > threshold

    def _record_interrupt_audio(self) -> None:
        """录制打断时的语音"""
        # 启动缓冲录音（最多 2 秒）
        max_buffer_duration = 2.0
        max_frames = int(max_buffer_duration * 16000 / 512)

        self._interrupt_buffer = []
        for _ in range(max_frames):
            audio_frame = self._audio_input.read_chunk()
            self._interrupt_buffer.append(audio_frame)

            # 如果静音超过 0.5 秒，停止录音
            # （这里简化处理，实际可以使用 VAD）

        logger.info(f"录制了 {len(self._interrupt_buffer)} 帧打断语音")

    def _handle_playback_complete(self) -> None:
        """处理 TTS 播放完成"""
        if self._tts_playback_end_time is None:
            self._tts_playback_end_time = time.time()
            logger.info("✅ TTS 播放完成")

        # 添加停顿
        pause_duration = 1.5
        time_since_playback_end = time.time() - self._tts_playback_end_time

        if time_since_playback_end < pause_duration:
            return

        logger.info(f"⏸️ 停顿完成 ({pause_duration}s)")

        if self._in_conversation:
            # 多轮对话模式：继续下一轮
            self._conversation_turn_count += 1
            logger.info("=" * 60)
            logger.info(f"🔄 进入第 {self._conversation_turn_count} 轮对话")
            logger.info("=" * 60)

            self._tts_playback_end_time = None
            self.transition_to(State.LISTENING)
        else:
            # 单次对话：返回 IDLE
            logger.info("=" * 60)
            logger.info("🔄 返回 IDLE 状态，等待下一次唤醒")
            logger.info("=" * 60)

            self._tts_playback_end_time = None
            self.transition_to(State.IDLE)
```

#### 配置

```yaml
# config.yaml

audio_quality:
  # 打断检测配置 (Phase 1.5 新增)
  interrupt:
    enabled: true                    # 是否启用智能打断
    detection_interval: 10           # 检测间隔（帧数）
    buffer_duration: 2.0             # 打断缓冲录音时长（秒）
```

---

### 3.2 上下文增强（P1）

#### 功能描述

优化多轮对话的上下文管理，使对话更自然流畅。

#### 增强点

1. **自动收尾**：多轮对话结束时自动道别
2. **智能延续**：识别用户的省略和延续性表达
3. **上下文记忆**：记住对话中的关键信息

#### 实现方案

```python
# 在 LLM 引擎中优化 system_prompt

def _build_conversation_context(self, user_text: str, turn_count: int) -> str:
    """
    构建对话上下文

    Args:
        user_text: 用户当前输入
        turn_count: 当前对话轮数

    Returns:
        str: 增强的上下文信息
    """
    # 第一轮：标准问候
    if turn_count == 1:
        return f"用户说：{user_text}\n请友好地回复。"

    # 多轮对话：添加延续性提示
    context_parts = [
        f"这是第 {turn_count} 轮对话。",
        "请根据之前的对话历史理解用户的省略或延续性表达。",
        f"用户当前说：{user_text}",
        "请简洁地回复（不超过50字）。"
    ]

    return "\n".join(context_parts)
```

---

### 3.3 上下文增强（P1）

#### 功能描述

为未来的功能扩展（如智能家居控制、音乐播放等）预留接口。

#### 设计方案

```python
class SkillManager:
    """技能管理器 (Phase 1.5 框架)"""

    def __init__(self, config: dict):
        self._skills = {}
        self._enabled = config.get("enabled", False)

    def register_skill(self, name: str, handler: callable) -> None:
        """注册技能"""
        self._skills[name] = handler
        logger.info(f"注册技能: {name}")

    def execute_skill(self, skill_name: str, params: dict) -> Any:
        """执行技能"""
        if skill_name in self._skills:
            return self._skills[skill_name](**params)
        else:
            logger.warning(f"技能不存在: {skill_name}")
            return None

# 示例技能
def skill_control_light(action: str, device_id: str = None):
    """控制灯光"""
    # 调用智能家居 API
    pass

def skill_play_music(song: str):
    """播放音乐"""
    # 调用音乐播放 API
    pass
```

#### 配置示例

```yaml
skills:
  enabled: false                     # Phase 1.5 默认禁用
  skills_list:
    - name: "control_light"
      handler: "src.skills.control_light"
    - name: "play_music"
      handler: "src.skills.play_music"
```

---

## 4. 工作流程设计

### 4.1 智能打断流程

```
┌─────────────────────────────────────────────┐
│  SPEAKING 状态（TTS 播放中）                │
│  ┌───────────────────────────────────┐    │
│  │  1. TTS 正在播放                  │    │
│  │  2. 每 10 帧检测一次语音活动      │    │
│  │  3. 检测到语音？                  │    │
│  │     ↓ YES                        │    │
│  │  4. 立即停止 TTS 播放            │    │
│  │  5. 缓冲录制 2 秒语音            │    │
│  │  6. 转入 LISTENING 状态          │    │
│  └───────────────────────────────────┘    │
└─────────────────────────────────────────────┘
```

### 4.2 整体对话流程（增强版）

```
┌───────────────────────────────────────────────────────────┐
│  用户: "派蒙"                                               │
│    ↓                                                        │
│  [WAKEUP] 播放回复: "我在，请吩咐"                          │
│    ↓                                                        │
│  [LISTENING] 录音中...                                       │
│    ↓                                                        │
│  用户: "今天天气怎么样？"                                    │
│    ↓                                                        │
│  [PROCESSING]                                               │
│    ├─ 音频质量检测 ✅                                      │
│    ├─ STT: "今天天气怎么样？"                               │
│    ├─ 文本质量检测 ✅                                       │
│    ├─ LLM: 生成回复                                          │
│    └─ TTS: 合成语音                                           │
│    ↓                                                        │
│  [SPEAKING] 播放回复中...                                    │
│    ├─ 每隔 300ms 检测语音活动                                │
│    └─ 检测到打断 → 立即停止                                 │
│    ↓                                                        │
│  用户: （打断）"明天呢？"                                   │
│    ↓                                                        │
│  [LISTENING] 录音中...                                       │
│    ↓                                                        │
│  [PROCESSING] LLM 生成回复（带上下文）                      │
│    ↓                                                        │
│  [SPEAKING] 播放回复...                                      │
│    ↓                                                        │
│  用户: （打断）"停止"                                       │
│    ↓                                                        │
│  [LISTENING] 识别为打断指令 → 进入下一轮对话                  │
│    ↓                                                        │
│  超时 → 返回 IDLE                                            │
└───────────────────────────────────────────────────────────┘
```

---

## 5. 配置设计

### 5.1 config.yaml 新增配置段

```yaml
# ========================================
# 音频质量检测配置 - Phase 1.5 增强
# ========================================
audio_quality:
  # Phase 1.4 配置保留
  enabled: true
  vad:
    adaptive_enabled: true
    base_threshold: 0.04
    adaptation_factor: 1.5
    noise_window_size: 100
    reset_interval: 300

  # Phase 1.5 新增：智能打断
  interrupt:
    enabled: true                    # 是否启用智能打断
    detection_interval: 10           # 检测间隔（帧数，约 300ms）
    buffer_duration: 2.0             # 打断缓冲录音时长（秒）
    min_speech_duration: 0.3         # 最小语音时长（秒）

  # 重试配置 (Phase 1.4 配置)
  max_retries: 3
  retry_prompts:
    # ... Phase 1.4 配置保留 ...

# ========================================
# 对话增强配置 - Phase 1.5
# ========================================
conversation:
  enabled: true

  # 上下文管理
  context_memory: true               # 是否启用上下文记忆
  max_turns: 10                      # 最大对话轮数

  # 自动收尾
  auto_farewell:
    enabled: true                    # 是否启用自动收尾
    idle_timeout: 8.0                # 空闲超时（秒）
    farewell_messages:
      - "好的，那先这样吧"
      - "嗯，好的"
      - "那下次再聊"

  # 延续性表达支持
  continuation_support: true       # 是否支持延续性表达

# ========================================
# 技能系统配置 - Phase 1.5（框架）
# ========================================
skills:
  enabled: false                    # Phase 1.5 默认禁用，预留扩展
  skills_list: []                    # 技能列表
```

---

## 6. 实施计划

### 6.1 开发任务拆解

| 阶段 | 任务 | 优先级 | 预计时间 |
|------|------|--------|----------|
| **1** | 智能打断功能 | P0 | 3小时 |
| **2** | 上下文增强 | P1 | 2小时 |
| **3** | 技能系统框架 | P1 | 2小时 |
| **4** | 测试与优化 | P0 | 3小时 |
| **总计** | | | **10 小时（1.5 天）** |

### 6.2 实施顺序

**阶段 1：智能打断（P0）**
- 修改 SPEAKING 状态更新逻辑
- 添加快速语音检测
- 添加打断缓冲录音
- 测试打断功能

**阶段 2：上下文增强（P1）**
- 优化 LLM system_prompt
- 添加自动收尾逻辑
- 测试多轮对话

**阶段 3：技能系统框架（P1）**
- 实现 SkillManager 基础框架
- 定义技能接口规范
- 编写示例技能

---

## 7. 测试计划

### 7.1 功能测试场景

| 场景 | 操作步骤 | 预期结果 |
|------|----------|----------|
| **智能打断** | TTS 播放中说"停止" | 立即停止播放，进入下一轮对话 |
| **打断继续对话** | TTS 播放中说"明天呢" | 停止播放，识别并回复关于明天天气 |
| **自动收尾** | 8秒无语音 | 播放"好的，那先这样吧"，返回 IDLE |
| **延续性表达** | 第2轮说"明天呢" | 理解为"明天天气怎么样" |

### 7.2 性能测试

| 指标 | 目标值 | 测试方法 |
|------|--------|----------|
| 打断检测延迟 | < 300ms | 计时测试 |
| 打断成功率 | > 90% | 统计测试 |
| CPU 占用增加 | < 10% | 性能监控 |
| 内存占用增加 | < 100MB | 内存监控 |

---

## 8. 风险与挑战

### 8.1 技术风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| 打断检测误判 | 正常播放被误打断 | 提高检测阈值，增加连续帧验证 |
| 增加代码复杂度 | 维护困难 | 提取为独立模块，添加注释 |

### 8.2 用户体验风险

| 风险 | 影响 | 缓解措施 |
|------|------|----------|
| 打断过于敏感 | 播放频繁被中断 | 可配置打断灵敏度 |
| 上下文记忆错误 | 对话逻辑混乱 | 限制记忆轮数，提供清理机制 |

---

## 9. 成功指标

### 9.1 量化指标

| 指标 | 当前值 (v1.4) | 目标值 (v1.5) | 测量方法 |
|------|----------------|---------------|----------|
| 打断成功率 | 0% | > 90% | 统计打断操作成功率 |
| 多轮对话完成率 | ~60% | > 75% | 统计完整对话比例 |
| 用户满意度 | 未知 | > 4.5/5.0 | 用户反馈 |

### 9.2 定性指标

- 交互更加自然流畅
- 可以随时打断不需要的回复
- 多轮对话更智能，理解上下文
- 对话更有人情味

---

## 10. 与现有架构的兼容性

### 10.1 向后兼容

- 新功能可通过配置启用/禁用
- 不影响现有功能
- 默认禁用高级功能，逐步启用

### 10.2 性能影响

| 功能 | CPU 增加 | 内存增加 | 说明 |
|------|----------|----------|------|
| 智能打断 | < 5% | < 50MB | 每 300ms 检测一次 |
| 上下文增强 | 0% | < 20MB | 仅优化 prompt |
| 技能框架 | 0% | < 10MB | 框架代码 |

---

## 11. 附录

### A. 小爱同学优秀特性总结

| 特性 | 实现建议 |
|------|----------|
| 多轮对话 | ✅ 已有基础，Phase 1.5 增强 |
| 智能打断 | ✅ Phase 1.5 实现 |
| 智能家居控制 | ⏳ Phase 1.5 框架预留 |
| 音乐播放 | ⏳ Phase 1.5 框架预留 |
| 情感化回复 | ⏳ Phase 1.5 优化提示语 |
| 声纹识别 | ⏳ Phase 2.0 考虑 |
| 个性化 | ⏳ Phase 2.0 考虑 |

### B. 参考资料

1. 小爱同学产品分析
2. 智能音箱交互设计最佳实践
3. Phase 1.4 需求文档

### C. 变更历史

| 版本 | 日期 | 变更内容 | 作者 |
|------|------|----------|------|
| 1.0 | 2026-01-23 | 初始版本 | Claude |

---

**文档结束**
